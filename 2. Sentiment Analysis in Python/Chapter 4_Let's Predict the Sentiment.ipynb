{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression of movie reviews\n",
    "In the video we learned that logistic regression is a common way to model a classification task, such as classifying the sentiment as positive or negative.\n",
    "\n",
    "In this exercise, you will work with the movies reviews dataset. The label column stores the sentiment, which is 1 when the review is positive, and 0 when negative. The text review has been transformed, using BOW, to numeric columns.\n",
    "\n",
    "Your task is to build a logistic regression model using the movies dataset and calculate its accuracy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import the logistic regression function.\n",
    "* Create and fit a logistic regression on the labels y and the features X.\n",
    "* Calculate the accuracy of the logistic regression model, using the default .score() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the vector of targets and matrix of features\n",
    "y = movies.label\n",
    "X = movies.drop('label', axis=1)\n",
    "\n",
    "# Build a logistic regression model and calculate the accuracy\n",
    "log_reg = LogisticRegression().fit(X, y)\n",
    "print('Accuracy of logistic regression: ', log_reg.score(X, y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression using Twitter data\n",
    "In this exercise, you will build a logistic regression model using the tweets dataset. The target is given by the airline_sentiment, which is 0 for negative tweets, 1 for neutral, and 2 for positive ones. So, in this case, you are given a multi-class classification task. Everything we learned about binary problems applies to multi-class classification problems as well.\n",
    "\n",
    "You will evaluate the accuracy of the model using the two different approaches from the slides.\n",
    "\n",
    "The logistic regression function and accuracy score have been imported for you."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Build and fit a logistic regression model using the defined X and y as arguments.\n",
    "* Calculate the accuracy of the logistic regression model.\n",
    "* Predict the labels.\n",
    "* Calculate the accuracy score using the predicted and true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the vector of targets and matrix of features\n",
    "y = tweets.airline_sentiment\n",
    "X = tweets.drop('airline_sentiment', axis=1)\n",
    "\n",
    "# Build a logistic regression model and calculate the accuracy\n",
    "log_reg = LogisticRegression().fit(X, y)\n",
    "print('Accuracy of logistic regression: ', log_reg.score(X,y))\n",
    "\n",
    "# Create an array of prediction\n",
    "y_predict = log_reg.predict(X)\n",
    "\n",
    "# Print the accuracy using accuracy score\n",
    "print('Accuracy of logistic regression: ', accuracy_score(y, y_predict))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and assess a model: movies reviews\n",
    "In this problem, you will build a logistic regression model using the movies dataset. The score is stored in the label column and is 1 when the review is positive, and 0 when negative. The text review has been transformed, using BOW, to numeric columns.\n",
    "\n",
    "You have already built a classifier but evaluated it using the same data employed in the training step. Make sure you now assess the model using an unseen test dataset. How does the performance of the model change when evaluated on the test set?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import the function required for a train/test split.\n",
    "* Perform the train/test split, specifying that 20% of the data should be used as a test set.\n",
    "* Train a logistic regression model.\n",
    "* Print out the accuracy of the model on the training and on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the vector of labels and matrix of features\n",
    "y = movies.label\n",
    "X = movies.drop('label', axis=1)\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a logistic regression model and print out the accuracy\n",
    "log_reg = LogisticRegression().fit(X_train,y_train)\n",
    "print('Accuracy on train set: ', log_reg.score(X_train, y_train))\n",
    "print('Accuracy on test set: ', log_reg.score(X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance metrics of Twitter data\n",
    "You will train a logistic regression model that predicts the sentiment of tweets and evaluate its performance on the test set using different metrics.\n",
    "\n",
    "A matrix X has been created for you. It contains features created with a BOW on the text column.\n",
    "\n",
    "The labels are stored in a vector called y. Vector y is 0 for negative tweets, 1 for neutral, and 2 for positive ones.\n",
    "Note that although we have 3 classes, it is still a classification problem. The accuracy still measures the proportion of correctly predicted instances. The confusion matrix will now be of size 3x3, each row will give the number of predicted cases for classes 2, 1, and 0, and each column - the true number of cases in class 2, 1, and 0.\n",
    "\n",
    "All required packages have been imported for you."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Perform the train/test split, and stratify by y.\n",
    "* Train a a logistic regression classifier.\n",
    "* Predict the performance on the test set.\n",
    "* Print the accuracy score and confusion matrix obtained on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123, stratify=y)\n",
    "\n",
    "# Train a logistic regression\n",
    "log_reg = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_predicted = log_reg.predict(X_test)\n",
    "\n",
    "# Print the performance metrics\n",
    "print('Accuracy score test set: ', accuracy_score(y_test, y_predicted))\n",
    "print('Confusion matrix test set: \\n', confusion_matrix(y_test, y_predicted)/len(y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and assess a model: product reviews data\n",
    "In this exercise, you will build a logistic regression using the reviews dataset, containing customers' reviews of Amazon products. The array y contains the sentiment : 1 if positive and 0 otherwise. The array X contains all numeric features created using a BOW approach. Feel free to explore them in the IPython Shell.\n",
    "\n",
    "Your task is to build a logistic regression model and calculate the accuracy and confusion matrix using the test dataset.\n",
    "\n",
    "The logistic regression and train/test splitting functions have been imported for you."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import the accuracy score and confusion matrix functions.\n",
    "* Split the data into training and testing, using 30% of it as a test set and set the random seed to 42.\n",
    "* Train a logistic regression model.\n",
    "* Print out the accuracy score and confusion matrix using the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the accuracy and confusion matrix\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Split the data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3, random_state=42)\n",
    "\n",
    "# Build a logistic regression\n",
    "log_reg = LogisticRegression().fit(X_train,y_train)\n",
    "\n",
    "# Predict the labels \n",
    "y_predict = log_reg.predict(X_test)\n",
    "\n",
    "# Print the performance metrics\n",
    "print('Accuracy score of test data: ', accuracy_score(y_test, y_predict))\n",
    "print('Confusion matrix of test data: \\n', confusion_matrix(y_test, y_predict)/len(y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict probabilities of movie reviews\n",
    "In this problem, you will build a logistic regression using the movies dataset. The labels are stored in the arrayy and the features in X.\n",
    "\n",
    "Train the model on the training data. Instead of predicting classes, predict the probabilities that each instance in the test set belongs to each of the two classes.\n",
    "\n",
    "The logistic regression and train/test splitting functions have been imported for you."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split the data into training and testing set.\n",
    "* Train a logistic regression model.\n",
    "* Predict the probabilities for class 0 and for class 1 of the testing data. Class 0 is located as the first column in the predicted probabilities, and class 1 is the second one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=321)\n",
    "\n",
    "# Train a logistic regression\n",
    "log_reg = LogisticRegression().fit(X_train,y_train)\n",
    "\n",
    "# Predict the probability of the 0 class\n",
    "prob_0 = log_reg.predict_proba(X_test)[:, 0]\n",
    "# Predict the probability of the 1 class\n",
    "prob_1 = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"First 10 predicted probabilities of class 0: \", prob_0[:10])\n",
    "print(\"First 10 predicted probabilities of class 1: \", prob_1[:10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Product reviews with regularization\n",
    "In this exercise, you will work once more with the reviews dataset of Amazon product reviews. A vector of labels y contains the sentiment : 1 if positive and 0 otherwise. The matrix X contains all numeric features created using a BOW approach.\n",
    "\n",
    "You will need to train two logistic regression models with different levels of regularization and compare how they perform on the test data. Remember that regularization is a way to control the complexity of the model. The more regularized a model is, the less flexible it is but the better it can generalize. Models with higher level of regularization are often less accurate than non-regularized ones."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split the data into a train and test sets.\n",
    "* Train a logistic regression with regularization parameter of 1000. Train a second logistic regression with regularization parameter equal to 0.001.\n",
    "* Print the accuracy scores of both models on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Train a logistic regression with regularization of 1000\n",
    "log_reg1 = LogisticRegression(C=1000).fit(X_train, y_train)\n",
    "# Train a logistic regression with regularization of 0.001\n",
    "log_reg2 = LogisticRegression(C=0.001).fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracies\n",
    "print('Accuracy of model 1: ', log_reg1.score(X_test, y_test))\n",
    "print('Accuracy of model 2: ', log_reg2.score(X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularizing models with Twitter data\n",
    "You will work with the Twitter data expressing customers' sentiment about airline companies. The X matrix of features and y vector of labels have been created for you. In addition, the training and testing split has been performed. You can work with the X_train, X_test, y_train and y_test arrays directly.\n",
    "\n",
    "You will train regularized and a more flexible models and evaluate them using different model performance metrics.\n",
    "\n",
    "All required packages have been imported for you."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train two logistic regressions: one with regularization parameter of 100 and a second of 0.1.\n",
    "* Print the accuracy scores of both models.\n",
    "* Print the confusion matrix of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a logistic regression with regularizarion parameter of 100\n",
    "log_reg1 = LogisticRegression(C=100).fit(X_train,y_train)\n",
    "# Build a logistic regression with regularizarion parameter of 0.1\n",
    "log_reg2 = LogisticRegression(C=0.1).fit(X_train,y_train)\n",
    "\n",
    "# Predict the labels for each model\n",
    "y_predict1 = log_reg1.predict(X_test)\n",
    "y_predict2 = log_reg2.predict(X_test)\n",
    "\n",
    "# Print performance metrics for each model\n",
    "print('Accuracy of model 1: ', accuracy_score(y_test, y_predict1))\n",
    "print('Accuracy of model 2: ', accuracy_score(y_test, y_predict2))\n",
    "print('Confusion matrix of model 1: \\n' , confusion_matrix(y_test, y_predict1)/len(y_test))\n",
    "print('Confusion matrix of model 2: \\n', confusion_matrix(y_test, y_predict2)/len(y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Word cloud and feature creation\n",
    "You will work with a sample of the reviews dataset throughout this exercise. It contains the review and score columns. Feel free to explore it in the IPython Shell.\n",
    "\n",
    "In the first step, you will build a word cloud using only positive reviews. The string positive_reviews has been created for you by concatenating the top 100 positive reviews.\n",
    "\n",
    "In the second step, you will create a new feature for the length of each review and add that new feature to the dataset.\n",
    "\n",
    "All the functions needed to plot a word cloud have been imported for you, as well as the word_tokenize function from the nltk module."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Call and create a word cloud image using the positive_reviews.\n",
    "* Display the generated image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and generate a word cloud image\n",
    "cloud_positives = WordCloud(background_color='white').generate(positive_reviews)\n",
    " \n",
    "# Display the generated wordcloud image\n",
    "plt.imshow(cloud_positives, interpolation='bilinear') \n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Don't forget to show the final image\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tokenize each item in the review column, using the word tokenizing function we have been working with.\n",
    "* Iterate over the created word_tokens list and find the length of each item in the list. Append that length to the empty len_tokens list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize each item in the review column\n",
    "word_tokens = [word_tokenize(review) for review in reviews.review]\n",
    "\n",
    "# Create an empty list to store the length of the reviews\n",
    "len_tokens = []\n",
    "\n",
    "# Iterate over the word_tokens list and determine the length of each item\n",
    "for i in range(len(word_tokens)):\n",
    "     len_tokens.append(len(word_tokens[i]))\n",
    "\n",
    "# Create a new feature for the lengh of each review\n",
    "reviews['n_words'] = len_tokens \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Building a vectorizer\n",
    "In this exercise, you are asked to build a TfIDf transformation of the review column in the reviews dataset. You are asked to specify the n-grams, stop words, the pattern of tokens and the size of the vocabulary arguments.\n",
    "\n",
    "This is the last step before we train a classifier to predict the sentiment of a review.\n",
    "\n",
    "Make sure you specify the maximum number of features properly, as a very large vocabulary size could disconnect your session."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import the Tfidf vectorizer and the default list of English stop words.\n",
    "* Build the Tfidf vectorizer, specifying - in this order - the following arguments: use as stop words the default list of English stop words; as n-grams use uni- and bi-grams;the maximum number of features should be 200; capture only words using the specified pattern.\n",
    "* Create a DataFrame using the Tfidf vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the TfidfVectorizer and default list of English stop words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "\n",
    "# Build the vectorizer\n",
    "vect = TfidfVectorizer(stop_words=ENGLISH_STOP_WORDS, ngram_range =(1, 2), max_features=200, token_pattern=r'\\b[^\\d\\W][^\\d\\W]+\\b').fit(reviews.review)\n",
    "\n",
    "# Create sparse matrix from the vectorizer\n",
    "X = vect.transform(reviews.review)\n",
    "\n",
    "# Create a DataFrame\n",
    "reviews_transformed = pd.DataFrame(X.toarray(), columns=vect.get_feature_names())\n",
    "print('Top 5 rows of the DataFrame: \\n', reviews_transformed.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Building a classifier\n",
    "This is the last step in the sentiment analysis prediction. We have explored and enriched our dataset with features related to the sentiment, and created numeric vectors from it.\n",
    "\n",
    "You will use the dataset that you built in the previous steps. Namely, it contains a feature for the length of reviews, and 200 features created with the Tfidf vectorizer.\n",
    "\n",
    "Your task is to train a logistic regression to predict the sentiment. The data has been imported for you and is called reviews_transformed. The target is called score and is binary : 1 when the product review is positive and 0 otherwise.\n",
    "\n",
    "Train a logistic regression model and evaluate its performance on the test data. How well does the model do?\n",
    "\n",
    "All the required packages have been imported for you."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Perform the train/test split, allocating 20% of the data to testing and setting the random seed to 456.\n",
    "* Train a logistic regression model.\n",
    "* Predict the class.\n",
    "* Print out the accuracy score and the confusion matrix on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "y = reviews_transformed.score\n",
    "X = reviews_transformed.drop('score', axis=1)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=456)\n",
    "\n",
    "# Train a logistic regression\n",
    "log_reg = LogisticRegression().fit(X_train, y_train)\n",
    "# Predict the labels\n",
    "y_predicted = log_reg.predict(X_test)\n",
    "\n",
    "# Print accuracy score and confusion matrix on test set\n",
    "print('Accuracy on the test set: ', accuracy_score(y_test, y_predicted))\n",
    "print(confusion_matrix(y_test, y_predicted)/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.6 (tags/v3.8.6:db45529, Sep 23 2020, 15:52:53) [MSC v.1927 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "92adc0dc7608e96a50ce5fb9acbd8bea0a01f16a513a55f8bb8294402fce5e61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
